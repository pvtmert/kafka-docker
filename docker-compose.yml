#!/usr/bin/env -S docker-compose -p kafka -f

version: "3.5"

networks:

  default:
    driver: bridge
    internal: false
    external: false

volumes:

  splunk_var:
    driver: local
    external: false

  splunk_etc:
    driver: local
    external: false

  kafka_logs:
    driver: local
    external: false

services:

  nodes:
    image: pvtmert/confluent:latest
    restart: "on-failure"
    #entrypoint: sh -c
    command: kafkanet
    build:
      context: ./
      dockerfile: dockerfile
      args: {}
    networks:
      default:
        aliases:
          - kafkanet
    expose:
      - 2181
      - 2888
      - 3888
      - 9092
      - 8771
      - 8772
      - 9991
      - 9992
    labels: []
    volumes:
      - kafka_logs:/home/confluent/logs:rw
    environment:
      SPLUNK_HEC_URL: https://splunk:8088
      SPLUNK_HEC_TOKEN: 8715c2d1-94af-4927-908a-23408c374328
    depends_on:
      - splunk
    deploy:
      endpoint_mode: dnsrr
      mode: replicated
      replicas: 3
      placement:
        constraints:
          - node.role == worker
        preferences:
          - spread: node.role
    healthcheck:
      test: timeout 10 bash -c 'cat </dev/null >/dev/tcp/0/9092'
      interval: 1m
      timeout: 10s
      retries: 3

  consumer:
    image: pvtmert/confluent:latest
    restart: "on-failure"
    hostname: consumer
    entrypoint:
      - /bin/bash
      - -xc
    command:
      - >
        SERVERS="$$(dig +short kafkanet | sed 's/$$/:9092/g')";
        kafka-console-consumer --topic hellokafka
        --bootstrap-server $${SERVERS//$$'\n'/,} &
        wait
    build:
      context: ./
      dockerfile: dockerfile
      args: {}
    networks:
      - default
    depends_on:
      - producer

  producer:
    image: pvtmert/confluent:latest
    restart: "on-failure"
    hostname: producer
    entrypoint:
      - /bin/bash
      - -xc
    command:
      - >
        SERVERS="$$(dig +short kafkanet | sed 's/$$/:9092/g')";
        top -bcHid5 | kafka-console-producer --topic hellokafka
        --broker-list $${SERVERS//$$'\n'/,} &
        wait
    build:
      context: ./
      dockerfile: dockerfile
      args: {}
    networks:
      - default
    depends_on:
      - nodes

  monitor:
    image: pvtmert/cmak:latest
    restart: "on-failure"
    hostname: splunk
    networks:
      - default
    expose:
      - 9000
    ports:
      - 9000:9000/tcp
    environment:
      ZK_HOSTS: kafkanet:2181,nodes:2181
    labels: []
    depends_on:
      - nodes

  splunk:
    image: splunk/splunk:7.2
    restart: "on-failure"
    hostname: splunk
    networks:
      - default
    expose:
      - 8000
      - 8088
      - 8089
      - 9997
    ports:
      - 8000:8000/tcp
    volumes:
      - splunk_var:/opt/splunk/var:rw
      - splunk_etc:/opt/splunk/etc:rw
      - kafka_logs:/tmp/logs:rw
    environment:
      SPLUNK_HEC_URL: https://splunk:8088
      SPLUNK_HEC_TOKEN: 8715c2d1-94af-4927-908a-23408c374328
      #SPLUNK_LICENSE_URI: Free
      SPLUNK_START_ARGS: --accept-license
      SPLUNK_PASSWORD: ${PASS:-password}
    labels: []

  extract:
    image: centos:7
    restart: "on-failure"
    entrypoint:
      - /bin/bash
      - -xc
    command:
      - |

        mkdir -p "/home/system/local"
        cp -vf "/configs/indexes.conf"  "/home/system/local/indexes.conf"
        cp -vf "/configs/serverclass.conf" "/home/system/local/serverclass.conf"

        until test -e /home/apps; do sleep 1; done
        find /configs/plugins -iname "*.tgz" -exec tar -C /home/apps -xzf "{}" ";"

        until test -e /home/deployment-apps; do sleep 1; done
        find /configs/plugins -iname "*.tgz" -exec tar -C /home/deployment-apps -xzf "{}" ";"

        mkdir -p "/home/apps/TA-kafka-streaming-platform/local"
        sed 's:^disabled = true$$:disabled = false:g' \
          "/home/apps/TA-kafka-streaming-platform/default/inputs.conf.sample" \
          | tee "/home/apps/TA-kafka-streaming-platform/local/inputs.conf"

        mkdir -p "/home/deployment-apps/TA-kafka-streaming-platform/local"
        sed 's:^disabled = true$$:disabled = false:g' \
          "/home/deployment-apps/TA-kafka-streaming-platform/default/inputs.conf.sample" \
          | tee "/home/deployment-apps/TA-kafka-streaming-platform/local/inputs.conf"

        mkdir -p "/home/apps/TA-telegraf-amd64/local"
        tee -a "/home/apps/TA-telegraf-amd64/local/inputs.conf" <<-EOF

          [http]
          disabled = 0

          [http://Telegraf]
          disabled = 0
          index = telegraf
          indexes = telegraf
          token = 8715c2d1-94af-4927-908a-23408c374328
        EOF

        mkdir -p "/home/deployment-apps/TA-telegraf-amd64/local"
        tee -a "/home/deployment-apps/TA-telegraf-amd64/local/inputs.conf" <<-EOF

          [http]
          disabled = 0

          [http://Telegraf]
          disabled = 0
          index = telegraf
          indexes = telegraf
          token = 8715c2d1-94af-4927-908a-23408c374328
        EOF

        cp -vf "/configs/telegraf.conf" "/home/apps/TA-telegraf-amd64/local/telegraf.conf"
        cp -vf "/configs/telegraf.conf" "/home/deployment-apps/TA-telegraf-amd64/local/telegraf.conf"

        chown --reference=/home -R /home
        chgrp --reference=/home -R /home
        exit
    volumes:
      - ./:/configs:ro
      - splunk_etc:/home:rw
    depends_on:
      - splunk

# TOPIC="hellokafka"
# SERVERS=$(dig +short kafkanet | sed 's/$/:9092/g')
# kafka-console-consumer --topic "${TOPIC}" --bootstrap-server "${SERVERS//$'\n'/,}"
# kafka-console-producer --topic "${TOPIC}" --broker-list "${SERVERS//$'\n'/,}"
