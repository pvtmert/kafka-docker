#!/usr/bin/env -S docker-compose -p kafka -f

version: "3.5"

networks:

  default:
    driver: bridge
    internal: false
    external: false

volumes:

  splunk_var:
    driver: local
    external: false

  splunk_etc:
    driver: local
    external: false

  kafka_logs:
    driver: local
    external: false

services:

  nodes:
    image: pvtmert/confluent:latest
    restart: "on-failure"
    #entrypoint: sh -c
    command: kafkanet
    build:
      context: ./
      dockerfile: ./dockerfile
      args: {}
    networks:
      default:
        aliases:
          - kafkanet
    expose:
      - 2181
      - 2888
      - 3888
      - 9092
      - 8771
      - 8772
      - 9991
      - 9992
    labels: []
    volumes:
      - kafka_logs:/home/confluent/logs:rw
    environment:
      NODE_ENV: docker
      NODE_LABEL: testing
      PROJECT_NAME: ${COMPOSE_PROJECT_NAME}
      SPLUNK_HEC_URL: https://splunk:8088
      SPLUNK_HEC_TOKEN: 5040c76a-d21d-42dc-8971-89324dc7f58f
    depends_on:
      - splunk
    deploy:
      endpoint_mode: dnsrr
      mode: replicated
      replicas: 3
      placement:
        constraints:
          - node.role == worker
        preferences:
          - spread: node.role
    healthcheck:
      test: timeout 10 bash -c 'cat </dev/null >/dev/tcp/0/9092'
      interval: 1m
      timeout: 10s
      retries: 3

  consumer:
    image: pvtmert/confluent:latest
    restart: "on-failure"
    hostname: consumer
    entrypoint:
      - /bin/bash
      - -xc
    command:
      - >
        SERVERS="$$(dig +short kafkanet | sed 's/$$/:9092/g')";
        kafka-console-consumer --topic hellokafka
        --bootstrap-server $${SERVERS//$$'\n'/,} &
        wait
    build:
      context: ./
      dockerfile: ./dockerfile
      args: {}
    networks:
      - default
    depends_on:
      - producer

  producer:
    image: pvtmert/confluent:latest
    restart: "on-failure"
    hostname: producer
    entrypoint:
      - /bin/bash
      - -xc
    command:
      - >
        SERVERS="$$(dig +short kafkanet | sed 's/$$/:9092/g')";
        top -bcHid5 | kafka-console-producer --topic hellokafka
        --broker-list $${SERVERS//$$'\n'/,} &
        wait
    build:
      context: ./
      dockerfile: ./dockerfile
      args: {}
    networks:
      - default
    depends_on:
      - nodes

  cmak-zk-fix:
    image: pvtmert/confluent:latest
    restart: "no"
    hostname: cmak-zk-fix
    entrypoint:
      - /bin/bash
      - -xc
    command:
      - |
        sleep 30 # give some time to boot
        zookeeper-shell kafkanet:2181 create /kafka-manager/mutex ""
        zookeeper-shell kafkanet:2181 create /kafka-manager/mutex/locks ""
        zookeeper-shell kafkanet:2181 create /kafka-manager/mutex/leases ""
        exit
    build:
      context: ./
      dockerfile: ./dockerfile
      args: {}
    networks:
      - default
    depends_on:
      - nodes

  manager:
    image: pvtmert/cmak:latest
    restart: "on-failure"
    hostname: splunk
    networks:
      - default
    build:
      context: ./cmak
      dockerfile: ./dockerfile
      args: {}
    expose:
      - 9000
    ports:
      - 9000:9000/tcp
    environment:
      ZK_HOSTS: kafkanet:2181,nodes:2181
      KAFKA_MANAGER_USERNAME: ${USER:-admin}
      KAFKA_MANAGER_PASSWORD: ${PASS:-password}
      KAFKA_MANAGER_AUTH_ENABLED: "true"
    labels: []
    depends_on:
      - nodes
      - cmak-zk-fix

  splunk:
    image: splunk/splunk:7.2
    restart: "on-failure"
    hostname: splunk
    networks:
      - default
    expose:
      - 8000
      - 8088
      - 8089
      - 9997
    ports:
      - 8000:8000/tcp
    volumes:
      - kafka_logs:/tmp/logs:rw
      - splunk_var:/opt/splunk/var:rw
      - splunk_etc:/opt/splunk/etc:rw
      - ./local:/opt/splunk/etc/apps/TA-telegraf-amd64/local:rw
      - ./local:/opt/splunk/etc/deployment-apps/TA-telegraf-amd64/local:rw
    environment:
      PROJECT_NAME: ${COMPOSE_PROJECT_NAME}
      SPLUNK_ENABLE_LISTEN: 9997
      #SPLUNK_HEC_URL: https://splunk:8088
      #SPLUNK_HEC_TOKEN: 8715c2d1-94af-4927-908a-23408c374328
      SPLUNK_USERNAME: ${USER:-admin}
      SPLUNK_PASSWORD: ${PASS:-password}
      SPLUNK_START_ARGS: --accept-license --no-prompt --answer-yes
      #SPLUNK_LICENSE_URI: Free
    labels: []

  extract:
    image: centos:7
    restart: "on-failure"
    entrypoint:
      - /bin/bash
      - -xc
    command:
      - |
        until test -e /home/apps; do sleep 1; done
        find /stuff -iname "*.tgz" -exec tar -C /home/apps -xzf "{}" ";"

        until test -e /home/deployment-apps; do sleep 1; done
        find /stuff -iname "*.tgz" -exec tar -C /home/deployment-apps -xzf "{}" ";"

        mkdir -p "/home/apps/TA-kafka-streaming-platform/local"
        sed 's:^disabled = true$$:disabled = false:g' \
          "/home/apps/TA-kafka-streaming-platform/default/inputs.conf.sample" \
          | tee "/home/apps/TA-kafka-streaming-platform/local/inputs.conf"

        mkdir -p "/home/deployment-apps/TA-kafka-streaming-platform/local"
        sed 's:^disabled = true$$:disabled = false:g' \
          "/home/deployment-apps/TA-kafka-streaming-platform/default/inputs.conf.sample" \
          | tee "/home/deployment-apps/TA-kafka-streaming-platform/local/inputs.conf"

        chown --reference=/home -R /home
        chgrp --reference=/home -R /home

        sleep 99
        exit
    volumes:
      - ./local:/configs:ro
      - ./plugins:/stuff:ro
      - splunk_etc:/home:rw
    depends_on:
      - splunk

# TOPIC="hellokafka"
# SERVERS=$(dig +short kafkanet | sed 's/$/:9092/g')
# kafka-console-consumer --topic "${TOPIC}" --bootstrap-server "${SERVERS//$'\n'/,}"
# kafka-console-producer --topic "${TOPIC}" --broker-list "${SERVERS//$'\n'/,}"
